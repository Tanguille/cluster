---
# yaml-language-server: $schema=https://raw.githubusercontent.com/cloudnative-pg/charts/refs/heads/main/charts/cluster/values.schema.json
apiVersion: postgresql.cnpg.io/v1
kind: Cluster
metadata:
  name: postgres16
  annotations:
    cnpg.io/skipEmptyWalArchiveCheck: enabled
spec:
  imageName: ghcr.io/cloudnative-pg/postgresql:18.2-standard-trixie@sha256:a1243f606cf12766c3b7106eaed5f5f61396c329a0475aada9bc228dc4ba5138
  instances: 3
  primaryUpdateStrategy: unsupervised
  primaryUpdateMethod: switchover
  storage:
    size: 20Gi
    storageClass: openebs-hostpath
  superuserSecret:
    name: cloudnative-pg-secret
  enableSuperuserAccess: true
  postgresql:
    parameters:
      max_connections: "400"
      shared_buffers: 1GB
      effective_cache_size: 3GB
      huge_pages: "try"
      # io_method: "io_uring" # Disabled: CloudNativePG runs PostgreSQL containers with capabilities: { drop: ["ALL"] }
      # which prevents io_uring from working. io_uring requires specific Linux capabilities (SYS_RESOURCE)
      # that CloudNativePG doesn't grant for security reasons. The worker method provides similar
      # asynchronous I/O performance using dedicated worker processes instead of io_uring.
      io_method: "worker"
      work_mem: 12MB
      maintenance_work_mem: 512MB
      # WAL tuning for fewer checkpoints/archives
      min_wal_size: 2GB
      max_wal_size: 8GB
      checkpoint_timeout: 15min
      checkpoint_completion_target: "0.9"
      wal_compression: "zstd"
      # Autovacuum tuned for many small/medium DBs with XID age protection
      autovacuum_vacuum_scale_factor: "0.02"
      autovacuum_analyze_scale_factor: "0.01"
      autovacuum_vacuum_threshold: "50"
      autovacuum_analyze_threshold: "25"
      autovacuum_vacuum_cost_limit: "2000"
      autovacuum_vacuum_cost_delay: "2ms"
      autovacuum_freeze_max_age: "100000000"
      vacuum_freeze_min_age: "50000000"
      vacuum_freeze_table_age: "75000000"
      default_statistics_target: "200"
      # I/O tuning for NVMe/LVM (openebs-lvm)
      random_page_cost: "1.1" # Default 4.0 (HDD-oriented), lowered for SSD/NVMe
      effective_io_concurrency: "200" # Default 16, increased for NVMe parallelism
    shared_preload_libraries:
      - "vchord.so"
    extensions:
      - name: vchord
        image:
          # renovate: datasource=docker depName=ghcr.io/tensorchord/vchord-scratch
          reference: ghcr.io/tensorchord/vchord-scratch:pg18-v1.0.0
      - name: vector
        image:
          # renovate: datasource=docker depName=ghcr.io/tensorchord/vchord-scratch
          reference: ghcr.io/tensorchord/vchord-scratch:pg18-v1.0.0
        dynamic_library_path:
          - /usr/lib/postgresql/18/lib
        extension_control_path:
          - /usr/share/postgresql/18/
  nodeMaintenanceWindow:
    inProgress: false
    reusePVC: true
  resources:
    requests:
      cpu: 300m
      memory: 1Gi
    limits:
      cpu: 2
      memory: 8Gi
      hugepages-2Mi: 2Gi
  monitoring:
    enablePodMonitor: true
  plugins:
    - name: &plugin barman-cloud.cloudnative-pg.io
      isWALArchiver: true
      parameters: &barmanParameters
        barmanObjectName: ceph-objectstore
        # Note: serverName version needs to be incremented
        # when recovering from an existing cnpg cluster
        serverName: postgres18
  # Note: previousCluster needs to be set to the name of the previous
  # cluster when recovering from an existing cnpg cluster
  bootstrap:
    recovery:
      source: &previousCluster postgres18
  # Note: externalClusters is needed when recovering from an existing cnpg cluster
  externalClusters:
    - name: *previousCluster
      plugin:
        enabled: true
        isWALArchiver: false
        name: *plugin
        parameters: *barmanParameters
